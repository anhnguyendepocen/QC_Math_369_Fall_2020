\documentclass[12pt]{article}

\include{preamble}

\newtoggle{professormode}
\toggletrue{professormode} %STUDENTS: DELETE or COMMENT this line



\title{MATH 369/650 Fall \the\year{} Homework \#2}

\author{Professor Adam Kapelner} %STUDENTS: write your name here

\iftoggle{professormode}{
\date{Due by email noon Tuesday, September 22, \the\year{} \\ \vspace{0.5cm} \small (this document last updated \today ~at \currenttime)}
}

\renewcommand{\abstractname}{Instructions and Philosophy}

\begin{document}
\maketitle

\iftoggle{professormode}{
\begin{abstract}
The path to success in this class is to do many problems. Unlike other courses, exclusively doing reading(s) will not help. Coming to lecture is akin to watching workout videos; thinking about and solving problems on your own is the actual ``working out.''  Feel free to \qu{work out} with others; \textbf{I want you to work on this in groups.}

Reading is still \textit{required}. For this homework set, review Math 241 concerning the normal distribution.

The problems below are color coded: \ingreen{green} problems are considered \textit{easy} and marked \qu{[easy]}; \inorange{yellow} problems are considered \textit{intermediate} and marked \qu{[harder]}, \inred{red} problems are considered \textit{difficult} and marked \qu{[difficult]} and \inpurple{purple} problems are extra credit. The \textit{easy} problems are intended to be ``giveaways'' if you went to class. Do as much as you can of the others; I expect you to at least attempt the \textit{difficult} problems. \qu{[MA]} are for those registered for the 600-level class and extra credit otherwise.

This homework is worth 100 points but the point distribution will not be determined until after the due date. See syllabus for the policy on late homework.

Up to 7 points are given as a bonus if the homework is typed using \LaTeX. Links to instaling \LaTeX~and program for compiling \LaTeX~is found on the syllabus. You are encouraged to use \url{overleaf.com}. If you are handing in homework this way, read the comments in the code; there are two lines to comment out and you should replace my name with yours and write your section. The easiest way to use overleaf is to copy the raw text from hwxx.tex and preamble.tex into two new overleaf tex files with the same name. If you are asked to make drawings, you can take a picture of your handwritten drawing and insert them as figures or leave space using the \qu{$\backslash$vspace} command and draw them in after printing or attach them stapled.

The document is available with spaces for you to write your answers. If not using \LaTeX, print this document and write in your answers. I do not accept homeworks which are \textit{not} on this printout. Keep this first page printed for your records.

\end{abstract}

\thispagestyle{empty}
\vspace{1cm}
NAME: \line(1,0){380}
\clearpage
}

\problem{In lecture 3, we did a two-sided binomial exact test. Now we will test the same theory (i.e. that the iPhone percentage in our class is different than the national average of 52.4\%), but use the approximate one-proportion z test to do it. Recall that our data was as follows: for $n=20$, the $\thetahathat = 0.60$ where the estimator we chose was the sample proportion.}

\begin{enumerate}

\easysubproblem{Write the alternative and null hypotheses again (from lecture 3).}\spc{0}

\easysubproblem{Write the asymptotic distribution of our estimator under the null hypothesis which we denote $\thetahat~|~H_0$. Answer in terms of standard error and round it to three decimal places. The answer is in lecture 4. Then illustrate the sampling distribution. Label the x-axis and provide tick marks on the x-axis.}\spc{8}

\easysubproblem{What theorem did you use to get the asymptotic distribution of the estimator? State the conditions of the theorem and the theorem's result.}\spc{2}

\easysubproblem{If we employ this asymptotic distribution of the estimator to test our theory, why is this no longer an \emph{exact test} but instead an \emph{approximate test}?}\spc{3}



\intermediatesubproblem{I want to make an apples-apples comparison with the two-sided binomial exact test from lecture 3. There $\alpha = 7.06\%$ so I want to use that same Type I error setting here. Compute the retainment region and rejection region (remember $\Theta = \zeroonecl$) and denote these two regions in your illustration in (b). To compute these regions, I'll provide you with the following fact: $\Phi(-1.808) = 3.53\%$ where $\Phi$ is the CDF of the standard normal rv. (These are the kind of facts that will be provided to you on exams).}\spc{2}

\easysubproblem{How does the retainment region compare here to the retainment region in the binomial exact test from lecture 3? Is the normal approximation to the binomial a good approximation in this case?}\spc{3}


\hardsubproblem{Write about a scenario where this approximation to the exactness will provide the wrong outcome. Would practical advice does this scenario teach you?}\spc{5}


\easysubproblem{Why is this test named the \emph{two-sided one-proportion z test}?}\spc{3}

\easysubproblem{Run the test and write your conclusion using an English sentence.}\spc{1}

\easysubproblem{What type of error could you have made?}\spc{0}


\easysubproblem{State the definition of Fisher's p-value.}\spc{3}

\intermediatesubproblem{Find the p-value of our estimate as a function of $\Phi$. Illustrate the p-value in the illustration in (b).}\spc{3}

\easysubproblem{Without computing the p-value explicitly, would it be above or below $\alpha = 7.06\%$? Is the estimate \emph{statistically significant}?}\spc{2}

\end{enumerate}


\problem{In lecture 5, we did a \emph{two-sided one sample z test}. Using the same data: $n=10$ and $\xbar = 70.5$, we will now test if the population that this sample was drawn from has a \emph{greater} mean than female height at $\alpha = 5\%$. According to an article \href{https://www.usablestats.com/lessons/normal}{(click here)}, female height is $\iid \normnot{65}{3.5^2}$.}

\begin{enumerate}

\easysubproblem{Write the alternative and null hypotheses. Remember our theory we want to prove is: our population mean is greater than the mean female height.}\spc{1}

\easysubproblem{Write the distribution of our estimator under the null hypothesis which we denote $\thetahat~|~H_0$. Assume the standard deviation is the same in our population as in the female height population. You will then calculate the standard error of $\Xbar$. Provide your final answer in terms of standard error and round it to two decimal places. Then illustrate the sampling distribution. Label the x-axis and provide tick marks on the x-axis.}\spc{9}


\intermediatesubproblem{Will this test be an \emph{exact test} or instead an \emph{approximate test}? Explain.}\spc{3}



\intermediatesubproblem{Compute the retainment region and rejection region (remember $\Theta = \reals$) and denote these two regions in your illustration in (b). To compute these regions, I'll provide you with the following fact: $\Phi(-1.645) = 5\%$.}\spc{4}

\easysubproblem{Why is this test called a \emph{one-sided one-sample z test}?}\spc{3}

\easysubproblem{Run the test and write your conclusion using an English sentence.}\spc{1}

\easysubproblem{What type of error could you have made?}\spc{0}

\intermediatesubproblem{Find the p-value of our estimate as a function of $\Phi$. Illustrate the p-value in the illustration in (b).}\spc{3}

\easysubproblem{Without computing the p-value explicitly, would it be above or below $\alpha = 5\%$? Is the estimate \emph{statistically significant}?}\spc{2}
 
\end{enumerate}


\problem{In the previous problem we did a \emph{one-sided one-sample z test}. We will now do a \emph{one-sided one-sample t test} Using the same data: $n=10$ and $\xbar = 70.5$, we will again test if the population that this sample was drawn from has a \emph{greater} mean than female height at $\alpha = 5\%$. According to \href{https://www.usablestats.com/lessons/normal}{this article}, female height is $\sim \normnot{65}{3.5^2}$. In this test, you need to compute $s = 2.07$, the sample standard deviation.}

\begin{enumerate}

\easysubproblem{Write the alternative and null hypotheses. Same as 2(a).}\spc{2}

\easysubproblem{Write the distribution of the \emph{standardized} estimator under the null hypothesis. Standardized means the mean is subtracted and you divide by the standard error. In contrast to 2(b), we do \emph{not assume} the standard deviation is the same in our population as in the female height population. Illustrate the sampling distribution. Label the x-axis. You do \emph{not} need to provide tick marks on the x-axis as this would require using a special calculator.}\spc{9}


\intermediatesubproblem{Will this test be an \emph{exact test} or instead an \emph{approximate test}? Explain.}\spc{3}



\intermediatesubproblem{Compute the retainment region and rejection region (remember $\Theta = \reals$) and denote these two regions in your illustration in (b). To compute these regions, I'll provide you with the following fact: $F_{T_9}(-1.833) = 5\%$ where $F_{T_9}$ is the CDF of Student's T distribution with 9 degree of freedom. (These are the kind of facts that will be provided to you on exams).}\spc{3}

\easysubproblem{Why is this test called a \emph{one-sided one sample t test}?}\spc{3}

\easysubproblem{Why is $\sigsq$ called a \emph{nuisance parameter}? Explain.}\spc{2}

\easysubproblem{Run the test and write your conclusion using an English sentence.}\spc{1}

\easysubproblem{What type of error could you have made?}\spc{0}

\intermediatesubproblem{Find the p-value of our estimate as a function of $F_{t_9}$. Illustrate the p-value in the illustration in (b).}\spc{3}

\easysubproblem{Without computing the p-value explicitly, would it be above or below $\alpha = 5\%$? Is the estimate \emph{statistically significant}?}\spc{1}
 
\end{enumerate}


\problem{In the previous problem, we needed to estimate the nuisance paramter $\sigsq$ in order to obtain Student's T distribution for the sampling distribution of the estimator, the sample average. If we naively estimated the population $\expe{X}$ with the sample average, the corresponding estimator for the population variance $\var{X}$ would be

\beqn
\hat{\sigma}^2 := \oneover{n}\sum_{i=1}^n (x_i - \theta)^2.
\eeqn}

\begin{enumerate}

\easysubproblem{Given only the data $\xoneton$, what is the practical problem with $\hat{\sigma}^2$ above?}\spc{3}

\easysubproblem{Solving this practical problem using an additional estimate, how would you define $\hat{\sigma}^2$?}\spc{1}

\easysubproblem{Let $S^2 = \frac{n}{n-1}\hat{\sigma}^2$. The constant $\frac{n}{n-1}$ is known as \href{https://en.wikipedia.org/wiki/Bessel\%27s_correction}{Bessel's correction}. Write the formula for $S^2$ only as a function of the data (the quantity $n$ is considered a function of the data, because it is the sample size which is the data's dimensionality).}\spc{1}

\intermediatesubproblem{Prove $S^2$ is unbiased to directly without computing $\expe{\hat{\sigma}^2}$ first (which is in the lecture). This is remarkably similar to the computation of $\expe{\hat{\sigma}^2}$ but different enough to make you think. Somewhere in this proof, you need to use the assumption that the DGP is $\iid$. Mark that location clearly.}\spc{11}


\easysubproblem{$S^2$ is an estimator for $\sigsq$. A natural estimator for $\sigma$ then is $S := \sqrt{S^2}$. Write the formula for $S$ below.}\spc{1}

\intermediatesubproblem{Even though $S^2$ is unbiased, it turns out that $S$ is biased due to Jensen's Inequality (which is taught in 368). Bessel's correction was a \qu{one-size fits all} correction to the bias for sample variance. Unfortunately, there's no analogous \qu{one-size fits all} correction to the bias for sample standard deviation; for every DGP it's different. Let the DGP be $\iid \normnot{\theta}{\sigsq}$ where neither parameter are known. In 368, an extra credit problem shows that 

\beqn
\expe{S} = \sqrt{\frac{2}{n-1}} \frac{\Gamma(n/2)}{\Gamma((n-1)/2)} \sigma
\eeqn

where $\Gamma()$ is called the \emph{gamma function}. Create a new estimator $S_*$ that's unbiased for the DGP $\iid \normnot{\theta}{\sigsq}$ and write its formula as a function of the data only (the quantity $n$ is considered a function of the data, because it is the sample size which is the data's dimensionality).

This looks harder than it is! You just need to mirror the trick used in class when we derived Bessel's Correction. You don't even need to know anything about the Gamma function.}\spc{2}

\hardsubproblem{[MA] Prove that $S$ is asymptotically unbiased (a calculus exercise).}\spc{5}


\extracreditsubproblem{Assume squared error loss and compute $R(S^2, \sigsq)$. Do this on a separate page.}\spc{3}


\end{enumerate}

\problem{We will now explore the concept of power and Type II errors. Let the DGP be $\iid \bernoulli{\theta}$.}


\begin{enumerate}


\easysubproblem{Let $H_0: \theta = .524$ and $H_a: \theta = .284$ and let $n = 20$. Find the approximate sampling distribution of $\thetahat = \Xbar$ using the CLT for both the null and alternative hypotheses. Leave in terms of standard error and compute to 3 decimal places.}\spc{3}

\easysubproblem{Would this be a left-sided test, a right-sided test or a two sided test? Explain.}\spc{2}

\easysubproblem{Illustrate the sampling distributions from the previous problem on one plot. Label the x-axis and provide tick marks.}\spc{10}

\easysubproblem{For $\alpha = 5\%$, compute the retainment region and rejection region (remember $\Theta = \zeroonecl$) and denote these two regions in your illustration in (c). To compute these regions, I'll provide you with the following fact: $\Phi(-1.645) = 5\%$.}\spc{3}

\easysubproblem{Write the definition of power (POW).}\spc{1}

\easysubproblem{Explain why, in general, you want POW to be large and close to 100\%.}\spc{3}

\intermediatesubproblem{Calculate POW as a function of $\Phi$.}\spc{7}

\easysubproblem{Assuming $H_a$, in the illustration in (c), shade in the area corresponding to the integral that computes POW using vertical stripes and shade in the area corresponding to the integral that computes Type II error using horizontal stripes. Don't write anything to answer this question.}\spc{-0.5}

\intermediatesubproblem{Let's do this generally. Let $H_0: \theta \geq \theta_0$ and $H_a: \theta = \theta_a < \theta_0$. Derive the power function $POW(\theta_0, \theta_a, n, \alpha)$ which uses the $\Phi$ function.}\spc{5}

\intermediatesubproblem{Prove that $\lim_{n\rightarrow \infty} POW(\theta_0, \theta_a, n, \alpha) = 1$.}\spc{3}


\intermediatesubproblem{Assume the DGP $\iid \normnot{\theta}{\sigsq}$ where $\sigsq$ is known. In a right-tailed test, we derived the power function in lecture 5 as 

\beqn
POW(\theta_0, \theta_a, n, \sigma, \alpha) = 1 - \Phi\parens{-\frac{\sqrt{n}}{\sigma} (\theta_a - \theta_0) + z_{1 - \alpha}}.
\eeqn

Prove that $\lim_{\sigma \rightarrow 0} POW(\theta_0, \theta_a, n, \sigma, \alpha) = 1$.
}\spc{5}



\extracreditsubproblem{Let $H_0: \theta \geq \theta_0$ and $H_a: \theta = \theta_a < \theta_0$. Calculate the power function for the binomial exact test at size $\alpha$. Do this on a separate page.}\spc{3}

\end{enumerate}
\end{document}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\problem{We will explore sampling in some detail herein. Some of the answers can be found by reading the \href{https://en.wikipedia.org/wiki/Sampling_(statistics)}{Wikipedia article}.}


\begin{enumerate}

\easysubproblem{Define \emph{population} and \emph{sample} and give the sizes of each using the notation we used in class.}\spc{3}

\easysubproblem{After selecting a sample, we take a \emph{survey}. In general, what is a survey? (It is also called \emph{measurement}). How does it relate to random variable models and realizations from random variables?}\spc{3}

\easysubproblem{In the survey we took in class, what were the possible values of a datum for each individual?}\spc{0.5}


\easysubproblem{For the survey we did in class, give three answers for the \qu{representative population}.}\spc{3}


\easysubproblem{Define \emph{simple random sample} (SRS).}\spc{4}

\intermediatesubproblem{Pick one of your answers from (d) and call that the population. Do you believe our class survey was an SRS? Why or why not?}\spc{2}

\intermediatesubproblem{We did not define \emph{sampling frame} in class. What is it and why is it important in practice?}\spc{4}

\intermediatesubproblem{What are some problems with SRS's?}\spc{3}

\easysubproblem{Explain why assuming the population size is infinite gives you an $\iid$ DGP when you use an SRS to sample individuals.}\spc{3}


\intermediatesubproblem{If we do not allow the population to be infinitely sized, is the DGP identically distributed? Would it be independent? Explain.}\spc{4}

\easysubproblem{Consider a Bernoulli survey. Split a population into subgroups A, B, C, D with subpopulation sizes $N_A$, $N_B$, $N_C$, $N_D$ (which all may be different quantities) and unknown number of positives of $\chi_A$, $\chi_B$, $\chi_C$, $\chi_D$ (which all may be different quantities). How do you calculate $\theta$ using these expressions?}\spc{1}


\intermediatesubproblem{Under what condition(s) would sampling from subpopulation B exclusively be representative of the whole population?}\spc{3}

\end{enumerate}

\problem{Here we will review estimates and estimators.}

\begin{enumerate}

\easysubproblem{Define statistic / estimate / statistical estimate.}\spc{2}

\easysubproblem{What is the difference between $\thetahathat$ and $\thetahat$?}\spc{1}

\easysubproblem{Is the $w$ the same function to compute both $\thetahathat$ and $\thetahat$? Yes / No}\spc{-0.5}

\hardsubproblem{For any DGP $\Xoneton$ which is independent and identically distributed where $\theta = \expe{X}$, we introduced the estimator $\thetahat = \Xbar$ that can be used to infer $\theta$. Think of another estimator that can be used to infer $\theta$.}\spc{3}

\easysubproblem{For any DGP $\Xoneton$ which is identically distributed where $\theta = \expe{X}$, prove that $\thetahat = \Xbar$ is always \emph{unbiased}.}\spc{3}

\intermediatesubproblem{skip}\spc{3}

\easysubproblem{If the DGP is $\Xoneton \iid \normnot{\theta}{\sigsq}$, show that the the risk under squared error loss for $\thetahat = \Xbar$ is the same regardless of $\theta$. Marked easy because it uses the previous question heavily.}\spc{3}


\hardsubproblem{[MA] Consider the scenario in 1(k). Sample subpopulation A with size $n_A$, sample subpopulation B with size $n_B$, sample subpopulation C with size $n_C$ and sample subpopulation D with size $n_D$, four different quantities such that $n = n_A + n_B + n_C + n_D$. Create an unbiased estimator for $\theta$ using these four samples (and prove that it is unbiased).}\spc{6}

\intermediatesubproblem{If the DGP is $\Xoneton \iid \bernoulli{\theta}$ and we choose the estimator $\thetahat_{\text{bad}} = 1/2$ (that is, degenerately 1/2 with probability 1). Why is this estimator a bad choice?} \spc{3}

\intermediatesubproblem{Graph the bias of $\thetahat_{\text{bad}}$ over all $\theta$. Label your axes.}\spc{4}

\intermediatesubproblem{Graph the risk of $\thetahat_{\text{bad}}$ under absolute loss. Label your axes.}\spc{4}

\hardsubproblem{Compare $\thetahat_{\text{bad}}$ to $\Xbar$ using the sup risk with squared error loss. How much better is $\Xbar$? With $n$ getting larger does it get better?}\spc{2}

\hardsubproblem{[MA] Invent a loss function that would make the risk for $\thetahat_{\text{bad}}$ better than $\Xbar$.}\spc{4}

\end{enumerate}


\problem{Here we will review theory testing from a conceptual point of view.}

\begin{enumerate}

\easysubproblem{What is \emph{theory testing} and how is it different from \emph{point estimation}?}\spc{3}

\easysubproblem{Give an example where theory testing is important.}\spc{3}


\easysubproblem{What are the two ways to go about convincing someone of your theory? Write them in the order we did in class since we will be referencing the \qu{first mode of convincing} and the \qu{second mode of convincing} in problems further on.}\spc{3}

\easysubproblem{Which way will win you more adherents and why?}\spc{3}

\easysubproblem{Regardless of how you do your convincing, why is it fundamentally impossible to prove your theory (in an absolute sense) in our context of statistical inference?}\spc{3}

\easysubproblem{The flavor of theory testing we traditionally do in statistical inference is called \emph{hypothesis testing}. What is a \emph{hypothesis}?}\spc{3}

\easysubproblem{In the second mode of convincing someone of your theory, which is your theory you want to convince others of, the null hypothesis or the alternative hypothesis?}\spc{0}

\easysubproblem{In the first mode of convincing someone of your theory, which is your theory you want to convince others of: the null hypothesis or the alternative hypothesis?}\spc{0}

\easysubproblem{In order to perform a hypothesis test (in either of the two modes), do you need to assume a DGP? Yes/No.}\spc{-0.5}

\easysubproblem{What are the three steps we mentioned to generate a test? Right them in the order we mentioned in class.}\spc{3}

\easysubproblem{For the third step, how do you know how far is a far enough departure? You need an additional parameter $\alpha$ that you (the statistician) is responsible for supplying to the theory testing. What is its role in the test?}\spc{3}

\easysubproblem{Although this parameter is fundamentally up to you, what is the scientific community's standard(s)?}\spc{1}

\easysubproblem{What is the \emph{retainment region} (RET)? What is the \emph{rejection region}? Why do you think the retainment region is sometimes called the \emph{non-critical region} and the rejection region is sometimes called the \emph{critical region}?}\spc{3}

\easysubproblem{What is the two possible outcomes of a hypothesis test? And which set does $\thetahathat$ belong to in each of these two possible outcomes?}\spc{2}

\easysubproblem{For each of these two possible results, which error could be made? Give the name of the error and describe it conceptually.}\spc{3}


\intermediatesubproblem{Circle the black dots next to the statement(s) which are \emph{always} true: 

\begin{itemize}
\item $\prob{\thetahat \in RET} = \alpha$
\item $\prob{\thetahat \notin RET} = \alpha$ 
\item $\prob{\text{Type I error}} = \alpha$
\item $\prob{\text{Type II error}} = \alpha$ 
\item $\prob{\text{Type I error}} + \prob{\text{Type II error}} = \alpha$ 
\item If $H_0$ is true, you cannot make a type I error.
\item If $H_0$ is true, you cannot make a type II error.
\item If $H_a$ is true, you cannot make a type I error.
\item If $H_a$ is true, you cannot make a type II error.
\item If $\alpha = 0$, $\prob{\text{Type II error}} = 0$ 
\item If $\alpha = 0$, $\prob{\text{Type II error}} = 1$ 
\item If $\alpha = 0$ and $H_a$ is true, $\prob{\text{Type II error}} = 0$ 
\item If $\alpha = 0$ and $H_a$ is true, $\prob{\text{Type II error}} = 1$
\item If $\alpha = 1$, $\prob{\text{Type II error}} = 0$ 
\item If $\alpha = 1$, $\prob{\text{Type II error}} = 1$ 
\item If $\alpha = 1$ and $H_a$ is true, $\prob{\text{Type II error}} = 0$ 
\item If $\alpha = 1$ and $H_a$ is true, $\prob{\text{Type II error}} = 1$
\item If $\alpha$ increases, the $\prob{\text{Type II error}}$ increases.
\item If $\alpha$ decreases, the $\prob{\text{Type II error}}$ increases.
\item After the test is completed, there is a mathematical way to determine if we made a Type I or Type II error.
\end{itemize}
}
\end{enumerate}


\problem{Here we will do a binomial exact test. We want to demonstrate that the iphone users in our class is greater than the national average (which is 52.4\%). Recall that our data was as follows: for $n=20$, the $\thetahathat = 0.60$ where the estimator we chose was the sample proportion.}

\begin{enumerate}

\easysubproblem{Write down $H_a$ then $H_0$.}\spc{2}

\easysubproblem{Declare your $\alpha$ level desired for this test. You do not need to justify it. It is what you are comfortable with.}\spc{0}


\intermediatesubproblem{Because we want to show something is greater than a point value, it is called a right-tailed test. In any test, we need to find the distribution (or approximate the distribution of) the estimator under the null hypothesis. Because we will reject on the right, why is the most conservative value of $\theta$ to choose when deriving the sampling distribution to be largest value in the null hypothesis region (in this case $\theta = \theta_0 = 0.524$)?}

\inred{This question unfortunately isn't answerable without knowing the concept of the \qu{power function} which we didn't get to until lecture 5. So you can skip it.}
\spc{3}

\easysubproblem{Regardless of if you understood the previous question or not, what is the exact sampling distribution given the null hypothesis? Marked easy because you can copy from class.}\spc{1}

\easysubproblem{Draw the PMF of the sampling distribution. Label all axes carefully and provide sufficient tick marks. Marked easy because you can copy from class.}\spc{9}

\easysubproblem{Indicate the RET and the rejection region in the above illustration. Use your $\alpha$. Everyone's answer may be different!}\spc{-0.5}

\intermediatesubproblem{Were you able to create a rejection region at your exact level of $\alpha$? Yes / no and why?}\spc{3}

\easysubproblem{Run the test. Write your conclusion in English.}\spc{3}

\end{enumerate}


%\hardsubproblem{Consider a Bernoulli survey. Split a population into subgroups A, B, C, D with subpopulation sizes $N_A$, $N_B$, $N_C$, $N_D$.}\spc{11}



\end{document}
